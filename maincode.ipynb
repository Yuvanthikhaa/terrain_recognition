{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "# Path to the directory containing the class folders\n",
    "dataset_dir = \"F:/Downloads/terrain_recognition/train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the ranges for slipperiness and roughness values for each class\n",
    "class_ranges = {\n",
    "    \"Grassy\": {\"slipperiness_min\": 0.1, \"slipperiness_max\": 0.5, \"roughness_min\": 0.2, \"roughness_max\": 0.7},\n",
    "    \"Marshy\": {\"slipperiness_min\": 0.3, \"slipperiness_max\": 0.7, \"roughness_min\": 0.4, \"roughness_max\": 0.8},\n",
    "    \"Rocky\": {\"slipperiness_min\": 0.5, \"slipperiness_max\": 0.9, \"roughness_min\": 0.6, \"roughness_max\": 0.9},\n",
    "    \"Sandy\": {\"slipperiness_min\": 0.2, \"slipperiness_max\": 0.6, \"roughness_min\": 0.1, \"roughness_max\": 0.5}\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a dictionary to store image paths, class labels, slipperiness, and roughness values\n",
    "image_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through each class folder\n",
    "for class_folder, class_info in class_ranges.items():\n",
    "    # Construct the full path to the class folder\n",
    "    class_folder_path = os.path.join(dataset_dir, class_folder)\n",
    "    \n",
    "    # Check if it's a directory\n",
    "    if os.path.isdir(class_folder_path):\n",
    "        # List all files in the class folder\n",
    "        image_files = os.listdir(class_folder_path)\n",
    "        \n",
    "        # Loop through each image file\n",
    "        for image_file in image_files:\n",
    "            # Construct the full path to the image file\n",
    "            image_path = os.path.join(class_folder_path, image_file)\n",
    "            \n",
    "            # Extract the class label from the image path\n",
    "            class_label = class_folder\n",
    "            \n",
    "            # Generate random slipperiness and roughness values within the specified range\n",
    "            slipperiness = random.uniform(class_info[\"slipperiness_min\"], class_info[\"slipperiness_max\"])\n",
    "            roughness = random.uniform(class_info[\"roughness_min\"], class_info[\"roughness_max\"])\n",
    "            \n",
    "            # Store the image data in a dictionary\n",
    "            image_info = {\n",
    "                \"image_path\": image_path,\n",
    "                \"class_label\": class_label,\n",
    "                \"slipperiness\": slipperiness,\n",
    "                \"roughness\": roughness\n",
    "            }\n",
    "            \n",
    "            # Append the image data to the list\n",
    "            image_data.append(image_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the image data (image path, class label, slipperiness, and roughness)\n",
    "for item in image_data:\n",
    "    print(\"Image path:\", item[\"image_path\"])\n",
    "    print(\"Class label:\", item[\"class_label\"])\n",
    "    print(\"Slipperiness:\", item[\"slipperiness\"])\n",
    "    print(\"Roughness:\", item[\"roughness\"])\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV3Large\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants\n",
    "IMAGE_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "NUM_CLASSES = 4  # Number of terrain classes (rocky, marshy, grassy, sandy)\n",
    "EPOCHS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation and preprocessing\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0 / 255.0,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data from folders\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'F:/Downloads/terrain_recognition/train',\n",
    "    target_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load validation data from folders\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    'F:/Downloads/terrain_recognition/val',\n",
    "    target_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the base MobileNetV3 model (without top layers)\n",
    "base_model = MobileNetV3Large(input_shape=(*IMAGE_SIZE, 3), include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add custom top layers for classification\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(512, activation='relu')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create separate output layers for terrain classification, slipperiness, and roughness predictions\n",
    "terrain_output = Dense(NUM_CLASSES, activation='softmax', name='terrain_output')(x)\n",
    "slipperiness_output = Dense(1, activation='linear', name='slipperiness_output')(x)\n",
    "roughness_output = Dense(1, activation='linear', name='roughness_output')(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the final model with multiple outputs\n",
    "model = Model(inputs=base_model.input, outputs=[terrain_output, slipperiness_output, roughness_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model with appropriate loss functions and metrics for each output\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss={'terrain_output': 'categorical_crossentropy', 'slipperiness_output': 'mean_squared_error', 'roughness_output': 'mean_squared_error'},\n",
    "    metrics={'terrain_output': 'accuracy', 'slipperiness_output': 'mae', 'roughness_output': 'mae'}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the checkpoint directory and file naming\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "checkpoint_path = os.path.join(checkpoint_dir, 'cp-{epoch:04d}.ckpt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a callback to save model checkpoints every 5 epochs\n",
    "cp_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    save_weights_only=True,\n",
    "    save_freq=5 * (len(train_generator) // BATCH_SIZE),  # Save every 5 epochs\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the weights if available (for resuming training)\n",
    "latest_checkpoint = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "if latest_checkpoint:\n",
    "    model.load_weights(latest_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model with the checkpoint callback\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=validation_generator,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[cp_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "model.save('terrain_quantities_classification_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "model = tf.keras.models.load_model('terrain_quantities_classification_model.h5')\n",
    "\n",
    "# Load and preprocess a single test image\n",
    "image_path = model = tf.keras.models.load_model('terrain_quantities_classification_model.h5')\n",
    "\n",
    "# Load and preprocess a single test image\n",
    "image_path = model = tf.keras.models.load_model('terrain_quantities_classification_model.h5')\n",
    "\n",
    "# Load and preprocess a single test image\n",
    "image_path = \"F:/Downloads/terrain_recognition/test/Marshy/Marshy (2)_4_17.png\"\n",
    "image = tf.keras.preprocessing.image.load_img(image_path, target_size=(224, 224))\n",
    "image = tf.keras.preprocessing.image.img_to_array(image)\n",
    "image = np.expand_dims(image, axis=0)\n",
    "image = image / 255.0  # Normalize the image\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(image)\n",
    "\n",
    "# Separate the predictions for terrain classification, slipperiness, and roughness\n",
    "terrain_predictions, slipperiness_predictions, roughness_predictions = predictions\n",
    "\n",
    "# Print the results\n",
    "print(\"Terrain Classification Predictions:\")\n",
    "terrain_labels = ['Rocky', 'Marshy', 'Grassy', 'Sandy']\n",
    "terrain_class = terrain_labels[np.argmax(terrain_predictions)]\n",
    "print(f\"Terrain: {terrain_class}\")\n",
    "\n",
    "print(\"Slipperiness Prediction:\")\n",
    "slipperiness_value = slipperiness_predictions[0][0]\n",
    "print(f\"Slipperiness Value: {slipperiness_value}\")\n",
    "\n",
    "print(\"Roughness Prediction:\")\n",
    "roughness_value = roughness_predictions[0][0]\n",
    "print(f\"Roughness Value: {roughness_value}\")\n",
    "image = tf.keras.preprocessing.image.load_img(image_path, target_size=(224, 224))\n",
    "image = tf.keras.preprocessing.image.img_to_array(image)\n",
    "image = np.expand_dims(image, axis=0)\n",
    "image = image / 255.0  # Normalize the image\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(image)\n",
    "\n",
    "# Separate the predictions for terrain classification, slipperiness, and roughness\n",
    "terrain_predictions, slipperiness_predictions, roughness_predictions = predictions\n",
    "\n",
    "# Print the results\n",
    "print(\"Terrain Classification Predictions:\")\n",
    "terrain_labels = ['Rocky', 'Marshy', 'Grassy', 'Sandy']\n",
    "terrain_class = terrain_labels[np.argmax(terrain_predictions)]\n",
    "print(f\"Terrain: {terrain_class}\")\n",
    "\n",
    "print(\"Slipperiness Prediction:\")\n",
    "slipperiness_value = slipperiness_predictions[0][0]\n",
    "print(f\"Slipperiness Value: {slipperiness_value}\")\n",
    "\n",
    "print(\"Roughness Prediction:\")\n",
    "roughness_value = roughness_predictions[0][0]\n",
    "print(f\"Roughness Value: {roughness_value}\")\n",
    "image = tf.keras.preprocessing.image.load_img(image_path, target_size=(224, 224))\n",
    "image = tf.keras.preprocessing.image.img_to_array(image)\n",
    "image = np.expand_dims(image, axis=0)\n",
    "image = image / 255.0  # Normalize the image\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(image)\n",
    "\n",
    "# Separate the predictions for terrain classification, slipperiness, and roughness\n",
    "terrain_predictions, slipperiness_predictions, roughness_predictions = predictions\n",
    "\n",
    "# Print the results\n",
    "print(\"Terrain Classification Predictions:\")\n",
    "terrain_labels = ['Rocky', 'Marshy', 'Grassy', 'Sandy']\n",
    "terrain_class = terrain_labels[np.argmax(terrain_predictions)]\n",
    "print(f\"Terrain: {terrain_class}\")\n",
    "\n",
    "print(\"Slipperiness Prediction:\")\n",
    "slipperiness_value = slipperiness_predictions[0][0]\n",
    "print(f\"Slipperiness Value: {slipperiness_value}\")\n",
    "\n",
    "print(\"Roughness Prediction:\")\n",
    "roughness_value = roughness_predictions[0][0]\n",
    "print(f\"Roughness Value: {roughness_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflowgpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
